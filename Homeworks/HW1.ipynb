{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Homework 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) How would you define Machine Learning?**\n",
    " * Machine learning is a way for computer programs to improve their performance on a task over time given more data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.**\n",
    "* In Supervised learning, you train the machine using data which is well \"labeled.\"\n",
    "* Unsupervised learning is a machine learning technique, where you do not need to supervise the model.\n",
    "* Supervised learning allows you to collect data or produce a data output from the previous experience.\n",
    "* Unsupervised machine learning helps you to finds all kind of unknown patterns in data.\n",
    "* For example, you will able to determine the time taken to reach back come base on weather condition, Times of the day and holiday.\n",
    "* For example, Baby can identify other dogs based on past supervised learning.\n",
    "* In a supervised learning model, input and output variables will be given while with unsupervised learning model, only input data will be given\n",
    "\n",
    "\n",
    "* **Supervised Learning**   --> Decision trees, Naive Bayes Classifier, Logistic regression\n",
    "* **Unsupervised Learning** --> K- Nearest neighbors, Clustering, Principal Componet Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) What are the test and validation set, and why would you want to use them?**\n",
    "\n",
    "* The training set is used to fit the models; the validation set is used to estimate prediction error for model selection; the test set is used for assessment of the generalization error of the final chosen model. Ideally, the test set should be kept in a “vault,” and be brought out only at the end of the data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?**\n",
    "  \n",
    "  #### DATA CLEANING : \n",
    "  * Data cleaning refers to techniques to ‘clean’ data by removing outliers, replacing missing values, smoothing noisy data, and correcting inconsistent data. \n",
    "  \n",
    "##### Missing values\n",
    "  \n",
    "  * Removing the training example: You can ignore the training example if the output label is missing (if it is a classification problem). This is usually discouraged as it leads to loss of data, as you are removing the attribute values that can add value to data set as well.\n",
    "\n",
    "  * Filling in missing value manually: This approach is time consuming, and not recommended for huge data sets. \n",
    "  \n",
    "  * Using a standard value to replace the missing value: The missing value can be replaced by a global constant such as ‘N/A’ or ‘Unknown’. This is a simple approach, but not foolproof.\n",
    "  \n",
    "  * Using central tendency (mean, median, mode) for attribute to replace the missing value: Based on data distribution, mean (in case of normal distribution) or median (for non-normal distribution) can be used to fill in for the missing value.\n",
    "  \n",
    "  * Using central tendency (mean, median, mode) for attribute belonging to same class to replace the missing value: This is the same as method 4, except that the measures of central tendency are specific to each class.\n",
    "  * Using the most probable value to fill in the missing value: Using algorithms like regression and decision tree, the missing values can be predicted and replaced.\n",
    "\n",
    " \n",
    "  ##### Noisy data\n",
    "  \n",
    "\n",
    "  * Binning: Using binning methods smooths sorted value by using the values around it. The sorted values are then divided into ‘bins’. There are various approaches to binning. Two of them are smoothing by bin means where each bin is replaced by the mean of bin’s values, and smoothing by bin medians where each bin is replaced by the median of bin’s values.\n",
    "  * Regression: Linear regression and multiple linear regression can be used to smooth the data, where the values are conformed to a function.\n",
    "  * Outlier analysis: Approaches such as clustering can be used to detect outliers and deal with them.\n",
    "  \n",
    "##### Data integration\n",
    "\n",
    "  * Data consolidation: The data is physically bought together to one data store. This usually involves Data Warehousing.\n",
    "  * Data propagation: Copying data from one location to another using applications is called data propagation. It can be synchronous or asynchronous and is event-driven.\n",
    "  * Data virtualization: An interface is used to provide a real-time and unified view of data from multiple sources. The data can be viewed from a single point of access.\n",
    "  \n",
    "  \n",
    "##### Data reduction\n",
    "\n",
    "  * Missing values ratio: Attributes that have more missing values than a threshold are removed.\n",
    "  * Low variance filter: Normalized attributes that have variance (distribution) less than a threshold are also removed, since little changes in data means less information.\n",
    "  * High correlation filter: Normalized attributes that have correlation coefficient more than a threshold are also removed, since similar trends means similar information is carried. Correlation coefficient is usually calculates using statistical methods such as Pearson’s chi-square value etc.\n",
    "  * Principal component analysis: Principal component analysis, or PCA, is a statistical method which reduces the numbers of attributes by lumping highly correlated attributes together. With each iteration, the initial features are reduced to principal components, with greater variance than the original set on the condition that they are uncorrelated with the preceding components. This method, however, only works for features with numerical values.\n",
    "\n",
    "Data transformation\n",
    "\n",
    "* Smoothing: Attribute/feature construction: New attributes are constructed from the given set of attributes.\n",
    "* Aggregation: Summary and Aggregation operations are applied on the given set of attributes to come up with new attributes.\n",
    "* Normalization: The data in each attribute is scaled between a smaller range e.g. 0 to 1 or -1 to 1.\n",
    "* Discretization: Raw values of the numeric attributes are replaced by discrete or conceptual intervals, which can in return be further organized into higher level intervals.\n",
    "* Concept hierarchy generation for nominal data: Values for nominal data are generalized to higher order concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) How you can explore countionus and discrete variables?**\n",
    "\n",
    "* **Discrete variable**\n",
    "  Discrete variables are numeric variables that have a countable number of values between any two values. A   discrete variable is always numeric. For example, the number of customer complaints or the number of flaws or defects.\n",
    "  \n",
    "  \n",
    "* **Continuous variable**\n",
    "    Continuous variables are numeric variables that have an infinite number of values between any two values. A continuous variable can be numeric or date/time. For example, the length of a part or the date and time a payment is received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)**\n",
    "\n",
    "   * We have continues variable in this plot and the histogram used to explore this data\n",
    "   * I tried for processing duplicate values process and mssing values process. Because same duplicate values end missing values in this data.\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"grafik.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python38564bitbasecondaa36d23ca368c4a06b017f2cbb1bc53a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
